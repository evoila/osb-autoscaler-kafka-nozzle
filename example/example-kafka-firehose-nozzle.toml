# This is example toml file to configure 'firehose-kafka-nozzle'.
# You can edit this file for your environment, but do not forget 
# to change its name to the default configuration file name or
# give the path of the file as a parameter as described in the README.

# All data will be distributed to nozzle with same subscription ID.
# https://github.com/cloudfoundry/loggregator#consuming-log-and-metric-data
subscription_id = "example-kafka-firehose-nozzle"

[cf]
# Endpoint where nozzle consumes logs
doppler_address = <doppler_address>

# To access to the firehoze and consume logs from there,
# you need an access token for that.
# 
# You can just set it at `token` property in this file.
# Or you can provide uaa endpoint and username/password.
# It automatically grants token before connecting.

# Endpoint where nozzle fetches the access token
# to read the firehose messages. 
uaa_address = <uaa_address>

# username & password to fetch the firehose access token
username = <username>
password = <password>

# token for subscribing data from firehose
# token = "np9q8b4qp3;vqo...."

#Credentials for the go cfclient connection
[gocfclient]
api = <api>
username = <username>
password = <password>

#Credentials for the go redis connection
[goredisclient]
addr = <ip_address>
password = <password>
db = <db>

[kafka]
# The list of kafka brokers IP
brokers = ["127.0.0.1:9092"]

# The producer retry logic
retry_max = 10
retry_backoff_ms = 500

# Topic kafka topic rule
# Each events are sent to the each topic on kafka
[kafka.topic]
log_message = "log"
log_message_fmt = "log-%s"
value_metric = "platformMetric"
